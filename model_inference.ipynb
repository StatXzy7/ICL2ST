{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config as CFG\n",
    "from models import *\n",
    "from dataset import *\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.5\n"
     ]
    }
   ],
   "source": [
    "#print the current scanpy version\n",
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold=5\n",
    "data='her2st' #### Change here to test different dataset 'her2st' 'cscc'\n",
    "\n",
    "prune='Grid' if data=='her2st' else 'NA'\n",
    "genes=171 if data=='cscc' else 785\n",
    "\n",
    "def pk_load(fold,mode='test',flatten=False,dataset='her2st',r=4,ori=True,adj=True,prune='Grid',neighs=8): #r=4 Hist2ST\n",
    "    assert dataset in ['her2st','cscc']\n",
    "    if dataset=='her2st':\n",
    "        dataset = CLIP_HER2ST(\n",
    "            train=(mode=='train'),fold=fold,flatten=flatten,\n",
    "            ori=ori,neighs=neighs,adj=adj,prune=prune,r=r\n",
    "        )\n",
    "    elif dataset=='cscc':\n",
    "        dataset = CLIP_SKIN(\n",
    "            train=(mode=='train'),fold=fold,flatten=flatten,\n",
    "            ori=ori,neighs=neighs,adj=adj,prune=prune,r=r\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "def build_loaders_inference():\n",
    "    print(\"Building loaders\")\n",
    "    trainset = pk_load(fold,'train',dataset=data,flatten=False,adj=True,ori=True,prune=prune)\n",
    "    train_loader = DataLoader(trainset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    testset = pk_load(fold,'test',dataset=data,flatten=False,adj=True,ori=True,prune=prune)\n",
    "    test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    print(\"Finished building loaders\")\n",
    "    return trainset, testset, train_loader, test_loader\n",
    "\n",
    "#2265x256, 2277x256\n",
    "def find_matches(spot_embeddings, query_embeddings, top_k=1):\n",
    "    #find the closest matches \n",
    "    spot_embeddings = torch.tensor(spot_embeddings)\n",
    "    query_embeddings = torch.tensor(query_embeddings)\n",
    "    query_embeddings = F.normalize(query_embeddings, p=2, dim=-1)\n",
    "    spot_embeddings = F.normalize(spot_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = query_embeddings @ spot_embeddings.T   #2277x2265\n",
    "    print(\"dot_similarity.shape = spots * reference_spots = \",dot_similarity.shape)\n",
    "    _, indices = torch.topk(dot_similarity.squeeze(0), k=top_k)\n",
    "    \n",
    "    return indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building loaders\n",
      "Test set names: ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "Train set names: ['F2', 'C6', 'D2', 'D6', 'G1', 'A2', 'B4', 'B6', 'C5', 'E2', 'B2', 'B5', 'D4', 'A3', 'C2', 'H3', 'D3', 'G3', 'C4', 'D5', 'H2', 'A5', 'C3', 'A4', 'A6', 'E3', 'F3', 'B3']\n",
      "Loading imgs...\n",
      "Loading metadata...\n",
      "Test set names: ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "Train set names: ['F2', 'C6', 'D2', 'D6', 'G1', 'A2', 'B4', 'B6', 'C5', 'E2', 'B2', 'B5', 'D4', 'A3', 'C2', 'H3', 'D3', 'G3', 'C4', 'D5', 'H2', 'A5', 'C3', 'A4', 'A6', 'E3', 'F3', 'B3']\n",
      "Loading imgs...\n",
      "Loading metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SGCL2ST/dataset.py:219: RuntimeWarning: invalid value encountered in cast\n",
      "  x = np.around(x).astype(int)\n",
      "/root/SGCL2ST/dataset.py:220: RuntimeWarning: invalid value encountered in cast\n",
      "  y = np.around(y).astype(int)\n",
      "/root/SGCL2ST/dataset.py:219: RuntimeWarning: invalid value encountered in cast\n",
      "  x = np.around(x).astype(int)\n",
      "/root/SGCL2ST/dataset.py:220: RuntimeWarning: invalid value encountered in cast\n",
      "  y = np.around(y).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building loaders\n",
      "Finished loading data\n"
     ]
    }
   ],
   "source": [
    "### Loading data\n",
    "\n",
    "trainset, testset, train_loader, test_loader = build_loaders_inference()\n",
    "train_loader = chain(train_loader, test_loader)\n",
    "\n",
    "print(\"Finished loading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_path =\"clip/best.pt\"\n",
    "model_path =\"clip/ICL2ST_HER2.pt\"\n",
    "if data =='cscc':\n",
    "    model_path =\"clip/ICL2ST_cSCC.pt\"\n",
    "save_path = \"clip/embeddings/\"\n",
    "model = myModel().cuda()\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    new_key = key.replace('module.', '')  # remove the prefix 'module.'\n",
    "    new_key = new_key.replace('well', 'spot') # for compatibility with prior naming\n",
    "    if \"image_encoder.gnn\" in new_key: # Special to GNN because GNN use torch_geometric.nn\n",
    "        new_key = new_key.replace(\"module_1.\",\"module_1.module.\")  \n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(\"Finished loading model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('G1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('C3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('F3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:04,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B5',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:05,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('C4',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:05,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B4',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:06,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('C2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:07,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('H3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D5',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:08,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('C6',)\n",
      "Processing image  ('C5',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:09,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:10,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('E2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:11,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A4',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:11,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('E3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D6',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:14,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('H2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:15,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('G3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:16,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:16,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B3',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:17,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B6',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:17,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:18,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A6',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:19,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('F2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:20,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D4',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:21,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A5',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:21,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('A1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:22,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('B1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:22,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('C1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:23,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('D1',)\n",
      "Processing image  ('E1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('F1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('G2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:27,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('H1',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "adj_dict = {}\n",
    "exp_dict = {}\n",
    "center_dict = {}\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader):\n",
    "        ID, patch, center, exp, adj, oris, sfs, centers = batch\n",
    "        print(\"Processing image \", ID)\n",
    "        B,N,C,H,W = patch.shape\n",
    "        patch = patch.reshape(B*N,C,H,W)  # (N,3,112,112)\n",
    "        if adj.dim() == 3:\n",
    "            adj = adj.squeeze(0)\n",
    "        if exp.dim() == 3:\n",
    "            exp = exp.squeeze(0)\n",
    "            centers = centers.squeeze().numpy()\n",
    "        adj_dict[ID] = adj \n",
    "        exp_dict[ID] = exp \n",
    "        center_dict[ID] = centers\n",
    "        \n",
    "        image_features = model.image_encoder(patch.cuda())\n",
    "        spot_features = model.spot_encoder(exp.cuda(), adj.cuda())\n",
    "        \n",
    "        image_embeddings = model.image_projection(image_features).cpu().numpy()\n",
    "        spot_embeddings = (model.spot_projection(spot_features.cuda()))\n",
    "        \n",
    "        spot_encoding = model.spot_autoencoder.encode(spot_embeddings, adj.cuda())\n",
    "        spot_reconstruction, extra = model.spot_autoencoder.decode(spot_encoding.cuda())\n",
    "        \n",
    "        spot_embeddings = spot_embeddings.cpu().numpy()\n",
    "        spot_encoding = spot_encoding.cpu().numpy()\n",
    "        spot_reconstruction = spot_reconstruction.cpu().numpy()\n",
    "        \n",
    "        # print(image_embeddings.shape)\n",
    "        # print(spot_embeddings.shape)\n",
    "        np.save(save_path + \"img_embeddings_\" + str(ID[0]) + \".npy\", image_embeddings.T)\n",
    "        np.save(save_path + \"spot_embeddings_\" + str(ID[0]) + \".npy\", spot_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['D2', 'C5', 'A2', 'C6', 'A6', 'D6', 'A4', 'B4', 'C4', 'C2', 'A3', 'B6', 'D3', 'B5', 'E2', 'F3', 'B2', 'H2', 'G1', 'A5', 'F2', 'E3', 'C3', 'D5', 'G3', 'H3', 'D4', 'B3', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1'])\n",
      "dict_keys(['D2', 'C5', 'A2', 'C6', 'A6', 'D6', 'A4', 'B4', 'C4', 'C2', 'A3', 'B6', 'D3', 'B5', 'E2', 'F3', 'B2', 'H2', 'G1', 'A5', 'F2', 'E3', 'C3', 'D5', 'G3', 'H3', 'D4', 'B3', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1'])\n",
      "dict_keys(['D2', 'C5', 'A2', 'C6', 'A6', 'D6', 'A4', 'B4', 'C4', 'C2', 'A3', 'B6', 'D3', 'B5', 'E2', 'F3', 'B2', 'H2', 'G1', 'A5', 'F2', 'E3', 'C3', 'D5', 'G3', 'H3', 'D4', 'B3', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1'])\n",
      "['D2', 'C5', 'A2', 'C6', 'A6', 'D6', 'A4', 'B4', 'C4', 'C2', 'A3', 'B6', 'D3', 'B5', 'E2', 'F3', 'B2', 'H2', 'G1', 'A5', 'F2', 'E3', 'C3', 'D5', 'G3', 'H3', 'D4', 'B3', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1']\n",
      "Test set names: ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "Train set names: ['F2', 'C6', 'D2', 'D6', 'G1', 'A2', 'B4', 'B3', 'C5', 'B6', 'E2', 'B5', 'D4', 'A3', 'C2', 'H3', 'D3', 'G3', 'C4', 'D5', 'H2', 'A5', 'C3', 'A4', 'A6', 'E3', 'F3', 'B2']\n"
     ]
    }
   ],
   "source": [
    "save_path = \"clip/embeddings/\"\n",
    "all_files = os.listdir(save_path)\n",
    "\n",
    "# exp_dict = {}\n",
    "# for batch in tqdm(train_loader):\n",
    "#     ID, patch, center, exp, adj, oris, sfs, *_ = batch\n",
    "#     print(ID)\n",
    "#     print(exp.shape)\n",
    "#     exp_dict[ID] = exp  # Assuming ID and exp are tensors, we fetch their first elements\n",
    "\n",
    "image_embeddings_dict = {}\n",
    "spot_embeddings_dict = {}\n",
    "ID_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    if file.endswith(\".npy\"):\n",
    "        # Extract the ID from the filename (e.g., A2, C3, etc.)\n",
    "        if data=='her2st': \n",
    "            if 'rep' not in file:\n",
    "                ID = file.split(\"_\")[2].split(\".\")[0]\n",
    "        elif data=='cscc':\n",
    "            if 'rep' in file:\n",
    "                ID = \"_\".join(file.split(\"_\")[2:-1]) + \"_\" + file.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        if (ID,) in adj_dict:\n",
    "            adj_dict[ID] = adj_dict.pop((ID,))\n",
    "        if (ID,) in exp_dict:\n",
    "            exp_dict[ID] = exp_dict.pop((ID,))\n",
    "        if (ID,) in center_dict:\n",
    "            center_dict[ID] = center_dict.pop((ID,))\n",
    "            \n",
    "        # Determine the type of file based on its prefix and load the data\n",
    "        if \"img_embeddings\" in file:\n",
    "            image_embeddings_dict[ID] = np.load(os.path.join(save_path, file))\n",
    "            ID_list.append(ID)\n",
    "        elif \"spot_embeddings\" in file:\n",
    "            spot_embeddings_dict[ID] = np.load(os.path.join(save_path, file))\n",
    "\n",
    "# Now, image_embeddings_dict and spot_embeddings_dict contain the required data\n",
    "print(image_embeddings_dict.keys())  # Should list all the image embedding IDs\n",
    "print(spot_embeddings_dict.keys())  # Should list all the spot embedding IDs\n",
    "print(exp_dict.keys())  # Should list all the spot embedding IDs\n",
    "print(ID_list)\n",
    "\n",
    "if data=='her2st':   \n",
    "    fold=[0,6,12,18,24,27,31,33]\n",
    "    test_ID = ['A1','B1','C1','D1','E1','F1','G2','H1']\n",
    "elif data=='cscc':\n",
    "    fold=[0,3,6,9]\n",
    "    test_ID = ['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
    "    \n",
    "# test_ID = [ID_list[i] for i in fold]\n",
    "print(\"Test set names:\", test_ID)\n",
    "train_ID = list(set(ID_list)-set(test_ID))\n",
    "print(\"Train set names:\",train_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "(256, 10139)\n",
      "(785, 10139)\n",
      "spot_key shape:  (10139, 256)\n",
      "expression_key shape:  (10139, 785)\n"
     ]
    }
   ],
   "source": [
    "#query\n",
    "# test_ID.remove('A1')\n",
    "print(test_ID)\n",
    "# image_query = [spot_embeddings_dict[ID] for ID in test_ID]\n",
    "# expression_gt = [exp_dict[ID].numpy().T for ID in test_ID]\n",
    "\n",
    "# image_train_data = [image_embeddings_dict[ID] for ID in train_ID]\n",
    "spot_train_data = [spot_embeddings_dict[ID] for ID in train_ID]\n",
    "expression_train_data = [exp_dict[ID].numpy().T for ID in train_ID]\n",
    "\n",
    "spot_key = np.concatenate(spot_train_data, axis=1)\n",
    "expression_key = np.concatenate(expression_train_data, axis=1)\n",
    "\n",
    "# print(image_query.shape)\n",
    "# print(expression_gt.shape)\n",
    "print(spot_key.shape)\n",
    "print(expression_key.shape)\n",
    "\n",
    "if spot_key.shape[1] != 256:\n",
    "    spot_key = spot_key.T\n",
    "    print(\"spot_key shape: \", spot_key.shape)\n",
    "if expression_key.shape[0] != spot_key.shape[0]:\n",
    "    expression_key = expression_key.T\n",
    "    print(\"expression_key shape: \", expression_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "\n",
    "def test(model,test,device='cuda'):\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    preds=None\n",
    "    ct=None\n",
    "    gt=None\n",
    "    loss=0\n",
    "    with torch.no_grad():\n",
    "        for patch, position, exp, adj, *_, center in tqdm(test):\n",
    "            patch, position, adj = patch.to(device), position.to(device), adj.to(device).squeeze(0)\n",
    "            pred = model(patch, position, adj)[0]\n",
    "            preds = pred.squeeze().cpu().numpy()\n",
    "            ct = center.squeeze().cpu().numpy()\n",
    "            gt = exp.squeeze().cpu().numpy()\n",
    "    adata = ad.AnnData(preds)\n",
    "    adata.obsm['spatial'] = ct\n",
    "    adata_gt = ad.AnnData(gt)\n",
    "    adata_gt.obsm['spatial'] = ct\n",
    "    return adata,adata_gt\n",
    "\n",
    "def cluster(adata,label):\n",
    "    idx = label != 'undetermined'\n",
    "    tmp=adata[idx]\n",
    "    l=label[idx]\n",
    "    print(\"cluster number:\",len(set(l)))\n",
    "    sc.pp.pca(tmp)\n",
    "    sc.tl.tsne(tmp)\n",
    "    kmeans = KMeans(n_clusters=len(set(l)), init=\"k-means++\", random_state=0).fit(tmp.obsm['X_pca'])\n",
    "    p=kmeans.labels_.astype(str)\n",
    "    lbl=np.full(len(adata),str(len(set(l))))\n",
    "    lbl[idx]=p\n",
    "    adata.obs['kmeans']=lbl\n",
    "    return p,round(ari_score(p,l),3)\n",
    "\n",
    "def get_R(data1,data2,dim=1,func=pearsonr):\n",
    "    adata1=data1.X\n",
    "    adata2=data2.X\n",
    "    r1,p1=[],[]\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim==1:\n",
    "            r,pv=func(adata1[:,g],adata2[:,g])\n",
    "        elif dim==0:\n",
    "            r,pv=func(adata1[g,:],adata2[g,:])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1=np.array(r1)\n",
    "    p1=np.array(p1)\n",
    "    return r1,p1\n",
    "\n",
    "def get_top_values(arr, num_top_values=10, lowest=False):\n",
    "    return sorted([(i, arr[i]) for i in range(len(arr))], key=lambda x: x[1], reverse=not lowest)[:num_top_values]\n",
    "top_k = 50\n",
    "results = {}\n",
    "top_results = {}\n",
    "selected_folds = [5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Processing Image A1\n",
      "image query shape:  (346, 256)\n",
      "expression_gt shape:  (346, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([346, 10139])\n",
      "pred.shape (346, 785)\n",
      "true.shape (346, 785)\n",
      "np.max(pred) 3.063084840774536\n",
      "np.max(true) 3.5403168\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.5604347543336636\n",
      "MSE across cells:  0.3341227162293125\n",
      "RMSE across cells:  0.5780334905775897\n",
      "Max correlation across genes: 0.6865587995609885\n",
      "Genes mean R:  0.21658230593425473\n",
      "Gene median R:  0.20637844165557437\n",
      "number of genes with correlation > 0.3:  180\n",
      "Top 50 Genes Mean Pearson Correlation: 0.46693745814690374\n",
      "Top 50 Genes Mean Pearson Correlation: 0.43699430610935225\n",
      "Fold A1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.6865587995609885, p_values: 1.5079007983123628e-49\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.6333224276797179, p_values: 3.428820600102361e-40\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.5728695180076125, p_values: 1.4464975876276516e-31\n",
      "Gene ID: 698, Gene Name: HLA-DRA, R: 0.5690747422420951, p_values: 4.399804823055054e-31\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.5678307451338096, p_values: 6.316126862386517e-31\n",
      "Gene ID: 397, Gene Name: IGFBP2, R: 0.5516623374732517, p_values: 6.054361168700133e-29\n",
      "Gene ID: 71, Gene Name: COMP, R: 0.5300034352600035, p_values: 1.876245824218985e-26\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.5260433668183588, p_values: 5.124424418563064e-26\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.5221839418364415, p_values: 1.3471946905904448e-25\n",
      "Gene ID: 217, Gene Name: JCHAIN, R: 0.5160141025354386, p_values: 6.158485199951145e-25\n",
      "Result of  A1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image B1\n",
      "image query shape:  (295, 256)\n",
      "expression_gt shape:  (295, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([295, 10139])\n",
      "pred.shape (295, 785)\n",
      "true.shape (295, 785)\n",
      "np.max(pred) 3.0228309631347656\n",
      "np.max(true) 3.494989\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.5695305426284444\n",
      "MSE across cells:  0.25455932710693896\n",
      "RMSE across cells:  0.5045387270635813\n",
      "Max correlation across genes: 0.735234432168712\n",
      "Genes mean R:  0.3607231191336116\n",
      "Gene median R:  0.3643029907191554\n",
      "number of genes with correlation > 0.3:  521\n",
      "Top 50 Genes Mean Pearson Correlation: 0.6169454044803298\n",
      "Top 50 Genes Mean Pearson Correlation: 0.6071796091278575\n",
      "Fold B1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.735234432168712, p_values: 2.068464030511506e-51\n",
      "Gene ID: 698, Gene Name: HLA-DRA, R: 0.6953643821131532, p_values: 6.099184144427515e-44\n",
      "Gene ID: 197, Gene Name: HLA-B, R: 0.6921536091819259, p_values: 2.15633364163306e-43\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.691315994789226, p_values: 2.9895903050003614e-43\n",
      "Gene ID: 704, Gene Name: STMN1, R: 0.6828796964529926, p_values: 7.55475826251635e-42\n",
      "Gene ID: 715, Gene Name: IGLC3, R: 0.6705061385107203, p_values: 7.1092762223936436e-40\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.6593697588546574, p_values: 3.5340838507975775e-38\n",
      "Gene ID: 582, Gene Name: NDUFB3, R: 0.6498363639312728, p_values: 8.79297514423221e-37\n",
      "Gene ID: 733, Gene Name: UBA52, R: 0.6473669028885166, p_values: 1.9841843714643604e-36\n",
      "Gene ID: 563, Gene Name: CXCL10, R: 0.6456054775892216, p_values: 3.529364519458135e-36\n",
      "Result of  B1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image C1\n",
      "image query shape:  (176, 256)\n",
      "expression_gt shape:  (176, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([176, 10139])\n",
      "pred.shape (176, 785)\n",
      "true.shape (176, 785)\n",
      "np.max(pred) 3.2423501014709473\n",
      "np.max(true) 3.4836807\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.6840413602850475\n",
      "MSE across cells:  0.20603387833297324\n",
      "RMSE across cells:  0.45390954862502425\n",
      "Max correlation across genes: 0.889923438922323\n",
      "Genes mean R:  0.3304086754081616\n",
      "Gene median R:  0.3270863923768987\n",
      "number of genes with correlation > 0.3:  458\n",
      "Top 50 Genes Mean Pearson Correlation: 0.6405442853220288\n",
      "Top 50 Genes Mean Pearson Correlation: 0.6032416753704493\n",
      "Fold C1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.889923438922323, p_values: 3.229546844811246e-61\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.849323877305572, p_values: 3.724045455100385e-50\n",
      "Gene ID: 328, Gene Name: MGP, R: 0.8471609156706805, p_values: 1.1652440213290406e-49\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.7879535583588313, p_values: 1.7279656255187827e-38\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.7838913097844602, p_values: 7.426512404284289e-38\n",
      "Gene ID: 431, Gene Name: CLDN4, R: 0.7807387673359021, p_values: 2.253557789765821e-37\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.7778494481114033, p_values: 6.1338975406252666e-37\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.7613861202707981, p_values: 1.4013253460526246e-34\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.7500987071112972, p_values: 4.5323820297552404e-33\n",
      "Gene ID: 736, Gene Name: CD74, R: 0.7221429650531311, p_values: 1.1766968093263872e-29\n",
      "Result of  C1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image D1\n",
      "image query shape:  (306, 256)\n",
      "expression_gt shape:  (306, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([306, 10139])\n",
      "pred.shape (306, 785)\n",
      "true.shape (306, 785)\n",
      "np.max(pred) 2.6765007972717285\n",
      "np.max(true) 3.1218235\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.6809289168653927\n",
      "MSE across cells:  0.24212232321393773\n",
      "RMSE across cells:  0.4920592679890683\n",
      "Max correlation across genes: 0.7663558745904661\n",
      "Genes mean R:  0.2537563731512594\n",
      "Gene median R:  0.24687254430255123\n",
      "number of genes with correlation > 0.3:  216\n",
      "Top 50 Genes Mean Pearson Correlation: 0.5019627556694377\n",
      "Top 50 Genes Mean Pearson Correlation: 0.4890495977868784\n",
      "Fold D1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.7663558745904661, p_values: 2.243628844378612e-60\n",
      "Gene ID: 89, Gene Name: ITGB6, R: 0.6519536464855005, p_values: 2.034894081273854e-38\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.6443713599131363, p_values: 2.7072076301252996e-37\n",
      "Gene ID: 275, Gene Name: C3, R: 0.6353273103919352, p_values: 5.398605300217304e-36\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.5822652858181465, p_values: 3.6277762644945356e-29\n",
      "Gene ID: 736, Gene Name: CD74, R: 0.5712967907035349, p_values: 6.598970889224623e-28\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.5710112658093427, p_values: 7.106304798839181e-28\n",
      "Gene ID: 783, Gene Name: NDRG1, R: 0.5612525131568614, p_values: 8.560489352537363e-27\n",
      "Gene ID: 191, Gene Name: RAB11FIP1, R: 0.5598473756381241, p_values: 1.2167519983662774e-26\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.5557823130792774, p_values: 3.3335919346279994e-26\n",
      "Result of  D1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image E1\n",
      "image query shape:  (587, 256)\n",
      "expression_gt shape:  (587, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([587, 10139])\n",
      "pred.shape (587, 785)\n",
      "true.shape (587, 785)\n",
      "np.max(pred) 3.2833139896392822\n",
      "np.max(true) 3.4946344\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.7161786687832891\n",
      "MSE across cells:  0.17064046122121626\n",
      "RMSE across cells:  0.4130865057360459\n",
      "Max correlation across genes: 0.5852980142710391\n",
      "Genes mean R:  0.19067183505271693\n",
      "Gene median R:  0.17979535574176259\n",
      "number of genes with correlation > 0.3:  151\n",
      "Top 50 Genes Mean Pearson Correlation: 0.42238879808089613\n",
      "Top 50 Genes Mean Pearson Correlation: 0.39624855843607465\n",
      "Fold E1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.5852980142710391, p_values: 2.948814501034082e-55\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.5587279740397001, p_values: 1.7033479668106563e-49\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.5533396999428493, p_values: 2.174373494032421e-48\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.540773717917586, p_values: 6.9155384229191596e-46\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.5339602714761347, p_values: 1.4228845391687566e-44\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.499393369747964, p_values: 2.374643282953667e-38\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.49692242918175455, p_values: 6.218397176098398e-38\n",
      "Gene ID: 765, Gene Name: LTF, R: 0.4951570885718833, p_values: 1.2310840334432692e-37\n",
      "Gene ID: 431, Gene Name: CLDN4, R: 0.49501753965720996, p_values: 1.299154304461438e-37\n",
      "Gene ID: 113, Gene Name: FDPS, R: 0.4897004580209343, p_values: 9.91378209761219e-37\n",
      "Result of  E1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image F1\n",
      "image query shape:  (691, 256)\n",
      "expression_gt shape:  (691, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([691, 10139])\n",
      "pred.shape (691, 785)\n",
      "true.shape (691, 785)\n",
      "np.max(pred) 3.2027430534362793\n",
      "np.max(true) 3.5189433\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.64563062276364\n",
      "MSE across cells:  0.2755524907929205\n",
      "RMSE across cells:  0.524930939070008\n",
      "Max correlation across genes: 0.595992362784775\n",
      "Genes mean R:  0.197093985035968\n",
      "Gene median R:  0.1958053747805049\n",
      "number of genes with correlation > 0.3:  141\n",
      "Top 50 Genes Mean Pearson Correlation: 0.37567192715505904\n",
      "Top 50 Genes Mean Pearson Correlation: 0.3605704437990822\n",
      "Fold F1 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.595992362784775, p_values: 1.1262138259648813e-67\n",
      "Gene ID: 636, Gene Name: LUC7L3, R: 0.431922459931408, p_values: 8.959036957724785e-33\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.43046744380958896, p_values: 1.5286826470738187e-32\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.4290359728497793, p_values: 2.579400718935407e-32\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.4240791183946161, p_values: 1.5484690557636545e-31\n",
      "Gene ID: 708, Gene Name: MYL9, R: 0.4190175467391331, p_values: 9.364448574040066e-31\n",
      "Gene ID: 202, Gene Name: PTGDS, R: 0.41514830562991534, p_values: 3.63109342311942e-30\n",
      "Gene ID: 580, Gene Name: TMBIM6, R: 0.41293271178667756, p_values: 7.827320859579045e-30\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.41266928192925956, p_values: 8.572528321474882e-30\n",
      "Gene ID: 368, Gene Name: RHOB, R: 0.41168627625361087, p_values: 1.2027631169731568e-29\n",
      "Result of  F1  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image G2\n",
      "image query shape:  (467, 256)\n",
      "expression_gt shape:  (467, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([467, 10139])\n",
      "pred.shape (467, 785)\n",
      "true.shape (467, 785)\n",
      "np.max(pred) 3.180065870285034\n",
      "np.max(true) 3.564969\n",
      "np.min(pred) 0.0\n",
      "np.min(true) 0.0\n",
      "The Prediction: prediction\n",
      "Cell Mean R:  0.6117345422947035\n",
      "MSE across cells:  0.27182720466019367\n",
      "RMSE across cells:  0.5213705061280257\n",
      "Max correlation across genes: 0.6666382524811522\n",
      "Genes mean R:  0.23508453802052778\n",
      "Gene median R:  0.23060998205548627\n",
      "number of genes with correlation > 0.3:  200\n",
      "Top 50 Genes Mean Pearson Correlation: 0.489690386190653\n",
      "Top 50 Genes Mean Pearson Correlation: 0.46558457219615046\n",
      "Fold G2 Top 10 genes with highest -log10 p-values:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.6666382524811522, p_values: 2.5058948260679485e-61\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.600420946296284, p_values: 4.415487414211521e-47\n",
      "Gene ID: 78, Gene Name: TMEM123, R: 0.590356811058605, p_values: 3.3648566115105405e-45\n",
      "Gene ID: 89, Gene Name: ITGB6, R: 0.582043105085631, p_values: 1.0778499186348899e-43\n",
      "Gene ID: 87, Gene Name: FAM193B, R: 0.5661055360053266, p_values: 6.321588497904581e-41\n",
      "Gene ID: 17, Gene Name: POSTN, R: 0.5636606609959276, p_values: 1.6303735601505702e-40\n",
      "Gene ID: 648, Gene Name: LUM, R: 0.5544468710892929, p_values: 5.402261380428494e-39\n",
      "Gene ID: 746, Gene Name: MYL12B, R: 0.5510354649265506, p_values: 1.921071224709158e-38\n",
      "Gene ID: 201, Gene Name: VIM, R: 0.5507249255705653, p_values: 2.15468431944482e-38\n",
      "Gene ID: 561, Gene Name: COL3A1, R: 0.5479232191483905, p_values: 6.035244430022502e-38\n",
      "Result of  G2  ended! \n",
      "\n",
      "\n",
      "\n",
      "Begin Processing Image H1\n",
      "image query shape:  (608, 256)\n",
      "expression_gt shape:  (613, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "dot_similarity.shape = spots * reference_spots =  torch.Size([608, 10139])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [54,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [62,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [8,0,0], thread: [94,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [8,0,0], thread: [118,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [8,0,0], thread: [125,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [8,0,0], thread: [126,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [69,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [70,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [77,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [78,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [85,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [86,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [93,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [94,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [4,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [5,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [6,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [12,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [13,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [14,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [20,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [21,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [22,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [29,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [9,0,0], thread: [30,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [23,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [30,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [31,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [37,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [38,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [39,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [45,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [46,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [47,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [53,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [54,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [55,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [62,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [63,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/SGCL2ST/model_inference.ipynb 单元格 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B93.114.160.254/root/SGCL2ST/model_inference.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(output_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B93.114.160.254/root/SGCL2ST/model_inference.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B93.114.160.254/root/SGCL2ST/model_inference.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m     pred_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mspot_encoder(torch\u001b[39m.\u001b[39;49mtensor(pred, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39;49mcuda(), adj\u001b[39m.\u001b[39;49mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B93.114.160.254/root/SGCL2ST/model_inference.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m     pred_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mspot_projection(torch\u001b[39m.\u001b[39mtensor(pred_features, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B93.114.160.254/root/SGCL2ST/model_inference.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     pred_encoding \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mspot_autoencoder\u001b[39m.\u001b[39mencode(torch\u001b[39m.\u001b[39mtensor(pred_embeddings, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mcuda(), adj\u001b[39m.\u001b[39mcuda())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/SGCL2ST/modules.py:106\u001b[0m, in \u001b[0;36mSpotEncoder.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs:\n\u001b[0;32m--> 106\u001b[0m         x \u001b[39m=\u001b[39m conv(x, edge_index) \u001b[39m+\u001b[39m x\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/SGCL2ST/modules.py:88\u001b[0m, in \u001b[0;36mSpotEncoder.ResGCNLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> 88\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x, edge_index)\n\u001b[1;32m     89\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x, edge_index)\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/SGCL2ST/modules.py:78\u001b[0m, in \u001b[0;36mSpotEncoder.GCNLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     76\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x)\n\u001b[1;32m     77\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m---> 78\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcn(x, edge_index)\n\u001b[1;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    212\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflow, x\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    214\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:91\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m num_nodes \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 91\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m add_remaining_self_loops(\n\u001b[1;32m     92\u001b[0m         edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     edge_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), ), dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m     96\u001b[0m                              device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/utils/loop.py:370\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    366\u001b[0m     loop_attr[edge_index[\u001b[39m0\u001b[39m][inv_mask]] \u001b[39m=\u001b[39m edge_attr[inv_mask]\n\u001b[1;32m    368\u001b[0m     edge_attr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m edge_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([edge_index[:, mask], loop_index], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    371\u001b[0m \u001b[39mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "for ID in test_ID:\n",
    "    print(\"Begin Processing Image\", ID)\n",
    "    image_query = spot_embeddings_dict[ID]\n",
    "    expression_gt = exp_dict[ID].numpy().T\n",
    "\n",
    "    method = \"weighted_average\" # \"average\" \"weighted_average\"\n",
    "    save_path = \"\"\n",
    "    if image_query.shape[1] != 256:\n",
    "        image_query = image_query.T\n",
    "        print(\"image query shape: \", image_query.shape)\n",
    "    if expression_gt.shape[0] != image_query.shape[0]:\n",
    "        expression_gt = expression_gt.T\n",
    "        print(\"expression_gt shape: \", expression_gt.shape)\n",
    "    if spot_key.shape[1] != 256:\n",
    "        spot_key = spot_key.T\n",
    "        print(\"spot_key shape: \", spot_key.shape)\n",
    "    if expression_key.shape[0] != spot_key.shape[0]:\n",
    "        expression_key = expression_key.T\n",
    "        print(\"expression_key shape: \", expression_key.shape)\n",
    "\n",
    "    if method == \"simple\":\n",
    "        indices = find_matches(spot_key, image_query, top_k=1)\n",
    "        matched_spot_embeddings_pred = spot_key[indices[:,0],:]\n",
    "        print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        matched_spot_expression_pred = expression_key[indices[:,0],:]\n",
    "        print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    if method == \"average\":\n",
    "        print(\"finding matches, using average of top 50 expressions\")\n",
    "        indices = find_matches(spot_key, image_query, top_k=50)\n",
    "        matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "        matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "        for i in range(indices.shape[0]):\n",
    "            matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0)\n",
    "            matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0)\n",
    "        \n",
    "        print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    if method == \"weighted_average\":\n",
    "        print(\"finding matches, using weighted average of top 50 expressions\")\n",
    "        indices = find_matches(spot_key, image_query, top_k=100)\n",
    "        # print(\"indices = \", indices)\n",
    "        matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "        matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "        for i in range(indices.shape[0]):\n",
    "            a = np.sum((spot_key[indices[i,0],:] - image_query[i,:])**2) #the smallest MSE\n",
    "            weights = np.exp(-(np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1)-a+1))\n",
    "            # weights = a/np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1)\n",
    "            # a = np.sqrt(np.sum((spot_key[indices[i,0],:] - image_query[i,:])**2)) #the smallest RMSE\n",
    "            # weights = np.exp(-(np.sqrt(np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1))-a+1))\n",
    "            \n",
    "            # sorted_indices = np.argsort(weights)[::-1]  # \n",
    "            # top_10_weights = weights[sorted_indices[:10]]\n",
    "            # least_10_weights = weights[sorted_indices[-10:]]\n",
    "            # print(\"Top 10 weights: \", top_10_weights)\n",
    "            # print(\"least 10 weights: \", least_10_weights)\n",
    "            \n",
    "            # if i == 0:\n",
    "            #     print(\"weights: \", weights)\n",
    "            matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0, weights=weights)\n",
    "            matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0, weights=weights)\n",
    "        \n",
    "        # print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        # print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    true = expression_gt\n",
    "    pred = matched_spot_expression_pred\n",
    "    adj = adj_dict[ID]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = './figures/show'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_features = model.spot_encoder(torch.tensor(pred, dtype=torch.float32).cuda(), adj.cuda())\n",
    "        pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
    "        pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
    "        pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n",
    "\n",
    "        pred_features = pred_features.cpu().numpy()\n",
    "        pred_embeddings = pred_embeddings.cpu().numpy()\n",
    "        pred_encoding = pred_encoding.cpu().numpy()\n",
    "        pred_reconstruction = pred_reconstruction.cpu().numpy()\n",
    "\n",
    "    print(\"pred.shape\",pred.shape)\n",
    "    print(\"true.shape\",true.shape)\n",
    "    print(\"np.max(pred)\",np.max(pred))\n",
    "    print(\"np.max(true)\",np.max(true))\n",
    "    print(\"np.min(pred)\",np.min(pred))\n",
    "    print(\"np.min(true)\",np.min(true))\n",
    "    \n",
    "    ####### Prediction PCC performance\n",
    "    mix = (pred + pred_reconstruction)/2\n",
    "    \n",
    "    def evaluate_gene_expression(pred, true, ID, top_k, fold, top_results, testset):\n",
    "        # Genewise correlation across cells\n",
    "        corr_cells = np.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            corr_cells[i] = np.corrcoef(pred[i, :], true[i, :])[0, 1]\n",
    "        # Remove NaN\n",
    "        corr_cells = corr_cells[~np.isnan(corr_cells)]\n",
    "        print(\"Cell Mean R: \", np.mean(corr_cells))\n",
    "        \n",
    "        # Calculate RMSE across cells\n",
    "        mse_cells = mean_squared_error(pred, true)\n",
    "        rmse_cells = sqrt(mse_cells)\n",
    "        print(\"MSE across cells: \", mse_cells)\n",
    "        print(\"RMSE across cells: \", rmse_cells)\n",
    "        \n",
    "        # Genewise correlation across genes\n",
    "        corr_genes = np.zeros(pred.shape[1])\n",
    "        p_values = np.zeros(pred.shape[1])\n",
    "        for i in range(pred.shape[1]):\n",
    "            # corr_genes[i] = np.corrcoef(pred[:, i], true[:, i])[0, 1]\n",
    "            corr_genes[i], p_values[i] = pearsonr(pred[:, i], true[:, i])\n",
    "        # Remove NaN\n",
    "        valid_indices = ~np.isnan(corr_genes)\n",
    "        corr_genes = corr_genes[valid_indices]\n",
    "        p_values = p_values[valid_indices]\n",
    "        \n",
    "        if corr_genes.size == 0:\n",
    "            print(\"corr_genes is an empty array\")\n",
    "        elif np.isnan(corr_genes).all():\n",
    "            print(\"corr_genes is an array of NaNs\")\n",
    "        else:\n",
    "            print(\"Max correlation across genes:\", np.nanmax(corr_genes))\n",
    "        \n",
    "        print(\"Genes mean R: \", np.mean(corr_genes))\n",
    "        print(\"Gene median R: \", np.median(corr_genes))\n",
    "        print(\"number of genes with correlation > 0.3: \", np.sum(corr_genes > 0.3))\n",
    "        \n",
    "        mlog_p_values = -np.log10(p_values)\n",
    "        # Top-k genes\n",
    "        # top_k_indices = np.argsort(corr_genes)[-top_k:] ## highest R\n",
    "        top_k_indices = np.argsort(mlog_p_values)[-top_k:] ## highest -log10 p-values\n",
    "        top_R_values = corr_genes[top_k_indices]\n",
    "        top_pred_values = pred[:, top_k_indices]\n",
    "        top_results[ID] = (top_R_values, top_pred_values)\n",
    "        print(f'Top {top_k} Genes Mean Pearson Correlation:', np.nanmean(top_R_values))\n",
    "        print(f'Top {top_k} Genes Mean Pearson Correlation:', np.nanmedian(top_R_values))\n",
    "        \n",
    "        # Get top gene correlations\n",
    "        top_R_values = get_top_values(corr_genes)\n",
    "        print('Fold', ID, \"Top 10 genes with highest -log10 p-values:\")\n",
    "        for gene_id, r_value in top_R_values:\n",
    "            gene_name = testset.gene_set[gene_id]\n",
    "            print(f\"Gene ID: {gene_id}, Gene Name: {gene_name}, R: {r_value}, p_values: {p_values[gene_id]}\")\n",
    "\n",
    "    # Example usage:\n",
    "    print(f\"The Prediction: prediction\")\n",
    "    evaluate_gene_expression(pred, true, ID, top_k, fold, top_results, testset)\n",
    "    # print(f\"\\n The Prediction Matrix: pred_reconstruction\")\n",
    "    # evaluate_gene_expression(pred_reconstruction, true, ID, top_k, fold, top_results, testset)\n",
    "    # print(f\"\\n The Prediction Matrix: mix\")\n",
    "    # evaluate_gene_expression(mix, true, ID, top_k, fold, top_results, testset)\n",
    "    \n",
    "    ####### Clustering \n",
    "    ### Change the type of pred to AnnData for the next clustering task\n",
    "    pred = sc.AnnData(pred)\n",
    "    pred.obsm['spatial'] = center_dict[ID]\n",
    "    true = ad.AnnData(true)\n",
    "    true.obsm['spatial'] = center_dict[ID]\n",
    "    pred_features = sc.AnnData(pred_features)\n",
    "    pred_features.obsm['spatial'] = center_dict[ID]\n",
    "    pred_embeddings = sc.AnnData(pred_embeddings)\n",
    "    pred_embeddings.obsm['spatial'] = center_dict[ID]\n",
    "    # pred_encoding = sc.AnnData(pred_encoding)\n",
    "    # pred_encoding.obsm['spatial'] = center_dict[ID]\n",
    "    pred_reconstruction = sc.AnnData(pred_reconstruction)\n",
    "    pred_reconstruction.obsm['spatial'] = center_dict[ID]\n",
    "    mix = sc.AnnData(mix)\n",
    "    mix.obsm['spatial'] = center_dict[ID]\n",
    "\n",
    "    if data=='her2st':\n",
    "        ####### Generate cluster figure\n",
    "        label = testset.label[ID]\n",
    "        # print(\"label = \",label)\n",
    "        # clus, ARI = cluster(pred, label)\n",
    "        # print('Fold:', fold, 'ARI:', ARI)\n",
    "        # title = f\"{ID} ARI = {ARI:.3f}\"  # Format title with ARI value   \n",
    "        # sc.pl.spatial(pred, img=testset.get_img(ID), color='kmeans', spot_size=112, title=title, save=f\"/mymodel_Her2_{ID}.pdf\")    \n",
    "        \n",
    "        \n",
    "        # clus, Top_ARI = cluster(top_pred_values, label)\n",
    "        # print('Fold:', fold, 'Top 100 ARI:', Top_ARI)\n",
    "        # clus, feature_ARI = cluster(pred_features, label)\n",
    "        # print('Fold:', fold, 'Expression features ARI:', feature_ARI)\n",
    "        # title = f\"{ID} ARI = {ARI:.3f}\"  # Format title with ARI value   \n",
    "        # sc.pl.spatial(pred_features, img=testset.get_img(ID), color='kmeans', spot_size=112, title=title, save=f\"/mymodel_Her2_{ID}_features.pdf\")   \n",
    "        \n",
    "        # clus, Emb_ARI = cluster(pred_embeddings, label)\n",
    "        # print('Fold:', fold, 'Expression Embeddings ARI:', Emb_ARI)\n",
    "        # title = f\"{ID} ARI = {Emb_ARI:.3f}\"  # Format title with ARI value   \n",
    "        # sc.pl.spatial(pred_embeddings, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_Emb.pdf\")\n",
    "\n",
    "        \n",
    "        # clus, Re_ARI = cluster(pred_reconstruction, label)\n",
    "        # print('Fold:', fold, 'Reconstruction ARI:', Re_ARI)\n",
    "        # title = f\"{ID} ARI = {Re_ARI:.3f}\"  # Format title with ARI value   \n",
    "        # sc.pl.spatial(pred_reconstruction, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_Reconstruction.pdf\")    \n",
    "        \n",
    "        # clus, mix_ARI = cluster(mix, label)\n",
    "        # print('Fold:', fold, 'Mixed Reconstruction ARI:', mix_ARI)\n",
    "        # title = f\"{ID} ARI = {mix_ARI:.3f}\"  # Format title with ARI value   \n",
    "        # sc.pl.spatial(mix, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_mix.pdf\") \n",
    "\n",
    "    print(\"Result of \", ID, \" ended! \")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # if save_path != \"\":\n",
    "    #     np.save(save_path + \"matched_spot_embeddings_pred.npy\", matched_spot_embeddings_pred.T)\n",
    "    #     np.save(save_path + \"matched_spot_expression_pred.npy\", matched_spot_expression_pred.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613, 785)\n",
      "(613, 785)\n",
      "(613, 256)\n",
      "(613, 785)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(pred_features.shape)\n",
    "print(pred_embeddings.shape)\n",
    "print(pred_reconstruction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
