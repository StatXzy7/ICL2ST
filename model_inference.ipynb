{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config as CFG\n",
    "from models import *\n",
    "from dataset import *\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.5\n"
     ]
    }
   ],
   "source": [
    "#print the current scanpy version\n",
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold=5\n",
    "data='cscc'\n",
    "prune='Grid' if data=='her2st' else 'NA'\n",
    "genes=171 if data=='cscc' else 785\n",
    "\n",
    "def pk_load(fold,mode='test',flatten=False,dataset='her2st',r=4,ori=True,adj=True,prune='Grid',neighs=8): #r=4 Hist2ST\n",
    "    assert dataset in ['her2st','cscc']\n",
    "    if dataset=='her2st':\n",
    "        dataset = CLIP_HER2ST(\n",
    "            train=(mode=='train'),fold=fold,flatten=flatten,\n",
    "            ori=ori,neighs=neighs,adj=adj,prune=prune,r=r\n",
    "        )\n",
    "    elif dataset=='cscc':\n",
    "        dataset = CLIP_SKIN(\n",
    "            train=(mode=='train'),fold=fold,flatten=flatten,\n",
    "            ori=ori,neighs=neighs,adj=adj,prune=prune,r=r\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "def build_loaders_inference():\n",
    "    print(\"Building loaders\")\n",
    "    trainset = pk_load(fold,'train',dataset=data,flatten=False,adj=True,ori=True,prune=prune)\n",
    "    train_loader = DataLoader(trainset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    testset = pk_load(fold,'test',dataset=data,flatten=False,adj=True,ori=True,prune=prune)\n",
    "    test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    print(\"Finished building loaders\")\n",
    "    return trainset, testset, train_loader, test_loader\n",
    "\n",
    "#2265x256, 2277x256\n",
    "def find_matches(spot_embeddings, query_embeddings, top_k=1):\n",
    "    #find the closest matches \n",
    "    spot_embeddings = torch.tensor(spot_embeddings)\n",
    "    query_embeddings = torch.tensor(query_embeddings)\n",
    "    query_embeddings = F.normalize(query_embeddings, p=2, dim=-1)\n",
    "    spot_embeddings = F.normalize(spot_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = query_embeddings @ spot_embeddings.T   #2277x2265\n",
    "    print(dot_similarity.shape)\n",
    "    _, indices = torch.topk(dot_similarity.squeeze(0), k=top_k)\n",
    "    \n",
    "    return indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building loaders\n",
      "All sample names: ['P2_ST_rep1', 'P2_ST_rep2', 'P2_ST_rep3', 'P5_ST_rep1', 'P5_ST_rep2', 'P5_ST_rep3', 'P9_ST_rep1', 'P9_ST_rep2', 'P9_ST_rep3', 'P10_ST_rep1', 'P10_ST_rep2', 'P10_ST_rep3']\n",
      "Test set names: ['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
      "Train set names: ['P2_ST_rep2', 'P9_ST_rep3', 'P9_ST_rep2', 'P2_ST_rep3', 'P10_ST_rep2', 'P5_ST_rep2', 'P5_ST_rep3', 'P10_ST_rep3']\n",
      "['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
      "Loading imgs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "All sample names: ['P2_ST_rep1', 'P2_ST_rep2', 'P2_ST_rep3', 'P5_ST_rep1', 'P5_ST_rep2', 'P5_ST_rep3', 'P9_ST_rep1', 'P9_ST_rep2', 'P9_ST_rep3', 'P10_ST_rep1', 'P10_ST_rep2', 'P10_ST_rep3']\n",
      "Test set names: ['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
      "Train set names: ['P2_ST_rep2', 'P9_ST_rep3', 'P9_ST_rep2', 'P2_ST_rep3', 'P10_ST_rep2', 'P5_ST_rep2', 'P5_ST_rep3', 'P10_ST_rep3']\n",
      "['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
      "Loading imgs...\n",
      "Loading metadata...\n",
      "Finished building loaders\n",
      "Finished loading data\n"
     ]
    }
   ],
   "source": [
    "### Loading data\n",
    "\n",
    "trainset, testset, train_loader, test_loader = build_loaders_inference()\n",
    "train_loader = chain(train_loader, test_loader)\n",
    "\n",
    "print(\"Finished loading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'clip/mymodel_HER2.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/ICL2ST/model_inference.ipynb 单元格 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# model = GraphCLIP().cuda()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m myModel()\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(model_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m new_state_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m state_dict\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'clip/mymodel_HER2.pt'"
     ]
    }
   ],
   "source": [
    "# datasize = [2378, 2349, 2277, 2265]\n",
    "# model_path =\"clip/best.pt\"\n",
    "# model_path = \"clip/mymodel_HER2.pt\"\n",
    "model_path =\"clip/ICL2ST_cSCC.pt\"\n",
    "save_path = \"clip/embeddings/\"\n",
    "# model = GraphCLIP().cuda()\n",
    "model = myModel().cuda()\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    new_key = key.replace('module.', '')  # remove the prefix 'module.'\n",
    "    new_key = new_key.replace('well', 'spot') # for compatibility with prior naming\n",
    "    if \"image_encoder.gnn\" in new_key: # Special to GNN because GNN use torch_geometric.nn\n",
    "        new_key = new_key.replace(\"module_1.\",\"module_1.module.\")  \n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(\"Finished loading model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image  ('P2_ST_rep2',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[785], expected input with shape [*, 785], but got input of size[646, 171]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/ICL2ST/model_inference.ipynb 单元格 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m center_dict[ID] \u001b[39m=\u001b[39m centers\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m image_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mimage_encoder(patch\u001b[39m.\u001b[39mcuda())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m spot_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mspot_encoder(exp\u001b[39m.\u001b[39;49mcuda(), adj\u001b[39m.\u001b[39;49mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m image_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mimage_projection(image_features)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m spot_embeddings \u001b[39m=\u001b[39m (model\u001b[39m.\u001b[39mspot_projection(spot_features\u001b[39m.\u001b[39mcuda()))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ICL2ST/modules.py:106\u001b[0m, in \u001b[0;36mSpotEncoder.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs:\n\u001b[0;32m--> 106\u001b[0m         x \u001b[39m=\u001b[39m conv(x, edge_index) \u001b[39m+\u001b[39m x\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ICL2ST/modules.py:76\u001b[0m, in \u001b[0;36mSpotEncoder.GCNLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> 76\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_norm(x)\n\u001b[1;32m     77\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     78\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgcn(x, edge_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[785], expected input with shape [*, 785], but got input of size[646, 171]"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "adj_dict = {}\n",
    "exp_dict = {}\n",
    "center_dict = {}\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader):\n",
    "        ID, patch, center, exp, adj, oris, sfs, centers = batch\n",
    "        print(\"Processing image \", ID)\n",
    "        B,N,C,H,W = patch.shape\n",
    "        patch = patch.reshape(B*N,C,H,W)  # (N,3,224,224)\n",
    "        if adj.dim() == 3:\n",
    "            adj = adj.squeeze(0)\n",
    "        if exp.dim() == 3:\n",
    "            exp = exp.squeeze(0)\n",
    "            centers = centers.squeeze().numpy()\n",
    "        adj_dict[ID] = adj \n",
    "        exp_dict[ID] = exp \n",
    "        center_dict[ID] = centers\n",
    "        \n",
    "        image_features = model.image_encoder(patch.cuda())\n",
    "        spot_features = model.spot_encoder(exp.cuda(), adj.cuda())\n",
    "        \n",
    "        image_embeddings = model.image_projection(image_features).cpu().numpy()\n",
    "        spot_embeddings = (model.spot_projection(spot_features.cuda()))\n",
    "        \n",
    "        spot_encoding = model.spot_autoencoder.encode(spot_embeddings, adj.cuda())\n",
    "        spot_reconstruction, extra = model.spot_autoencoder.decode(spot_encoding.cuda())\n",
    "        \n",
    "        spot_embeddings = spot_embeddings.cpu().numpy()\n",
    "        spot_encoding = spot_encoding.cpu().numpy()\n",
    "        spot_reconstruction = spot_reconstruction.cpu().numpy()\n",
    "        \n",
    "        # print(image_embeddings.shape)\n",
    "        # print(spot_embeddings.shape)\n",
    "        np.save(save_path + \"img_embeddings_\" + str(ID[0]) + \".npy\", image_embeddings.T)\n",
    "        np.save(save_path + \"spot_embeddings_\" + str(ID[0]) + \".npy\", spot_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['H1', 'A3', 'A4', 'H2', 'E3', 'D6', 'B6', 'B4', 'A6', 'A5', 'G3', 'E2', 'D3', 'C6', 'H3', 'C2', 'D5', 'C3', 'F3', 'C5', 'A2', 'B2', 'F2', 'B5', 'B3', 'D2', 'G1', 'C4', 'D4', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2'])\n",
      "dict_keys(['H1', 'A3', 'A4', 'H2', 'E3', 'D6', 'B6', 'B4', 'A6', 'A5', 'G3', 'E2', 'D3', 'C6', 'H3', 'C2', 'D5', 'C3', 'F3', 'C5', 'A2', 'B2', 'F2', 'B5', 'B3', 'D2', 'G1', 'C4', 'D4', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2'])\n",
      "dict_keys(['A3', 'A4', 'H2', 'E3', 'D6', 'B6', 'B4', 'A6', 'A5', 'G3', 'E2', 'D3', 'C6', 'H3', 'C2', 'D5', 'C3', 'F3', 'C5', 'A2', 'B2', 'F2', 'B5', 'B3', 'D2', 'G1', 'C4', 'D4', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1'])\n",
      "['H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'A3', 'A4', 'H2', 'E3', 'D6', 'B6', 'B4', 'A6', 'A5', 'G3', 'E2', 'D3', 'C6', 'H3', 'C2', 'D5', 'C3', 'F3', 'C5', 'A2', 'B2', 'F2', 'B5', 'B3', 'D2', 'G1', 'C4', 'D4', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "Test set names: ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "Train set names: ['D5', 'B5', 'B3', 'G1', 'A4', 'H2', 'C3', 'C2', 'E3', 'A2', 'D3', 'B6', 'B4', 'B2', 'G3', 'H3', 'F2', 'D2', 'A6', 'C5', 'F3', 'C4', 'A5', 'C6', 'D4', 'D6', 'A3', 'E2']\n"
     ]
    }
   ],
   "source": [
    "save_path = \"clip/embeddings/\"\n",
    "all_files = os.listdir(save_path)\n",
    "\n",
    "# exp_dict = {}\n",
    "# for batch in tqdm(train_loader):\n",
    "#     ID, patch, center, exp, adj, oris, sfs, *_ = batch\n",
    "#     print(ID)\n",
    "#     print(exp.shape)\n",
    "#     exp_dict[ID] = exp  # Assuming ID and exp are tensors, we fetch their first elements\n",
    "\n",
    "image_embeddings_dict = {}\n",
    "spot_embeddings_dict = {}\n",
    "ID_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    if file.endswith(\".npy\"):\n",
    "        # Extract the ID from the filename (e.g., A2, C3, etc.)\n",
    "        if data=='her2st': \n",
    "            if 'rep' not in file:\n",
    "                ID = file.split(\"_\")[2].split(\".\")[0]\n",
    "        elif data=='cscc':\n",
    "            if 'rep' in file:\n",
    "                ID = \"_\".join(file.split(\"_\")[2:-1]) + \"_\" + file.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        if (ID,) in adj_dict:\n",
    "            adj_dict[ID] = adj_dict.pop((ID,))\n",
    "        if (ID,) in exp_dict:\n",
    "            exp_dict[ID] = exp_dict.pop((ID,))\n",
    "        if (ID,) in center_dict:\n",
    "            center_dict[ID] = center_dict.pop((ID,))\n",
    "            \n",
    "        # Determine the type of file based on its prefix and load the data\n",
    "        if \"img_embeddings\" in file:\n",
    "            image_embeddings_dict[ID] = np.load(os.path.join(save_path, file))\n",
    "            ID_list.append(ID)\n",
    "        elif \"spot_embeddings\" in file:\n",
    "            spot_embeddings_dict[ID] = np.load(os.path.join(save_path, file))\n",
    "\n",
    "# Now, image_embeddings_dict and spot_embeddings_dict contain the required data\n",
    "print(image_embeddings_dict.keys())  # Should list all the image embedding IDs\n",
    "print(spot_embeddings_dict.keys())  # Should list all the spot embedding IDs\n",
    "print(exp_dict.keys())  # Should list all the spot embedding IDs\n",
    "print(ID_list)\n",
    "\n",
    "if data=='her2st':   \n",
    "    fold=[0,6,12,18,24,27,31,33]\n",
    "    test_ID = ['A1','B1','C1','D1','E1','F1','G2','H1']\n",
    "elif data=='cscc':\n",
    "    fold=[0,3,6,9]\n",
    "    test_ID = ['P2_ST_rep1', 'P5_ST_rep1', 'P9_ST_rep1', 'P10_ST_rep1']\n",
    "    \n",
    "# test_ID = [ID_list[i] for i in fold]\n",
    "print(\"Test set names:\", test_ID)\n",
    "train_ID = list(set(ID_list)-set(test_ID))\n",
    "print(\"Train set names:\",train_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G2', 'H1']\n",
      "(256, 10139)\n",
      "(785, 10139)\n",
      "spot_key shape:  (10139, 256)\n",
      "expression_key shape:  (10139, 785)\n"
     ]
    }
   ],
   "source": [
    "#query\n",
    "# test_ID.remove('A1')\n",
    "print(test_ID)\n",
    "# image_query = [spot_embeddings_dict[ID] for ID in test_ID]\n",
    "# expression_gt = [exp_dict[ID].numpy().T for ID in test_ID]\n",
    "\n",
    "# image_train_data = [image_embeddings_dict[ID] for ID in train_ID]\n",
    "spot_train_data = [spot_embeddings_dict[ID] for ID in train_ID]\n",
    "expression_train_data = [exp_dict[ID].numpy().T for ID in train_ID]\n",
    "\n",
    "spot_key = np.concatenate(spot_train_data, axis=1)\n",
    "expression_key = np.concatenate(expression_train_data, axis=1)\n",
    "\n",
    "# print(image_query.shape)\n",
    "# print(expression_gt.shape)\n",
    "print(spot_key.shape)\n",
    "print(expression_key.shape)\n",
    "\n",
    "if spot_key.shape[1] != 256:\n",
    "    spot_key = spot_key.T\n",
    "    print(\"spot_key shape: \", spot_key.shape)\n",
    "if expression_key.shape[0] != spot_key.shape[0]:\n",
    "    expression_key = expression_key.T\n",
    "    print(\"expression_key shape: \", expression_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "\n",
    "def test(model,test,device='cuda'):\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    preds=None\n",
    "    ct=None\n",
    "    gt=None\n",
    "    loss=0\n",
    "    with torch.no_grad():\n",
    "        for patch, position, exp, adj, *_, center in tqdm(test):\n",
    "            patch, position, adj = patch.to(device), position.to(device), adj.to(device).squeeze(0)\n",
    "            pred = model(patch, position, adj)[0]\n",
    "            preds = pred.squeeze().cpu().numpy()\n",
    "            ct = center.squeeze().cpu().numpy()\n",
    "            gt = exp.squeeze().cpu().numpy()\n",
    "    adata = ad.AnnData(preds)\n",
    "    adata.obsm['spatial'] = ct\n",
    "    adata_gt = ad.AnnData(gt)\n",
    "    adata_gt.obsm['spatial'] = ct\n",
    "    return adata,adata_gt\n",
    "\n",
    "def cluster(adata,label):\n",
    "    idx = label != 'undetermined'\n",
    "    tmp=adata[idx]\n",
    "    l=label[idx]\n",
    "    print(\"cluster number:\",len(set(l)))\n",
    "    sc.pp.pca(tmp)\n",
    "    sc.tl.tsne(tmp)\n",
    "    kmeans = KMeans(n_clusters=len(set(l)), init=\"k-means++\", random_state=0).fit(tmp.obsm['X_pca'])\n",
    "    p=kmeans.labels_.astype(str)\n",
    "    lbl=np.full(len(adata),str(len(set(l))))\n",
    "    lbl[idx]=p\n",
    "    adata.obs['kmeans']=lbl\n",
    "    return p,round(ari_score(p,l),3)\n",
    "\n",
    "def get_R(data1,data2,dim=1,func=pearsonr):\n",
    "    adata1=data1.X\n",
    "    adata2=data2.X\n",
    "    r1,p1=[],[]\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim==1:\n",
    "            r,pv=func(adata1[:,g],adata2[:,g])\n",
    "        elif dim==0:\n",
    "            r,pv=func(adata1[g,:],adata2[g,:])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1=np.array(r1)\n",
    "    p1=np.array(p1)\n",
    "    return r1,p1\n",
    "\n",
    "def get_top_values(arr, num_top_values=10, lowest=False):\n",
    "    return sorted([(i, arr[i]) for i in range(len(arr))], key=lambda x: x[1], reverse=not lowest)[:num_top_values]\n",
    "top_k = 50\n",
    "results = {}\n",
    "top_results = {}\n",
    "selected_folds = [5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image A1\n",
      "image query shape:  (346, 256)\n",
      "expression_gt shape:  (346, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([346, 10139])\n",
      "(346, 785)\n",
      "(346, 785)\n",
      "3.03171968460083\n",
      "3.5403168\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.5540155412618086\n",
      "MSE across cells:  0.3321556132846759\n",
      "RMSE across cells:  0.5763294312150612\n",
      "Max correlation across genes: 0.6266315942844823\n",
      "Fold A1 mean correlation across genes:  0.20242404514684853\n",
      "Fold A1 number of genes with correlation > 0.3:  142\n",
      "Fold A1 :Top 50 Genes Mean Pearson Correlation: 0.4512985892220058\n",
      "Fold A1 Top 10 genes with highest correlation:\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.6266315942844823\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.6091376789158621\n",
      "Gene ID: 698, Gene Name: HLA-DRA, R: 0.5775756990842519\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.5751661266024105\n",
      "Gene ID: 217, Gene Name: JCHAIN, R: 0.5509313155780583\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.549650460091019\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.4916885546219226\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.49068684042083816\n",
      "Gene ID: 245, Gene Name: IGHM, R: 0.4893198847490368\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.4883893957326827\n",
      "cluster number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.067\n",
      "cluster number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.118\n",
      "cluster number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.13\n",
      "cluster number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.107\n",
      "cluster number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.079\n",
      "Processing Image B1\n",
      "image query shape:  (295, 256)\n",
      "expression_gt shape:  (295, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([295, 10139])\n",
      "(295, 785)\n",
      "(295, 785)\n",
      "3.126047372817993\n",
      "3.494989\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.5675477011055287\n",
      "MSE across cells:  0.25619484341671256\n",
      "RMSE across cells:  0.5061569355612077\n",
      "Max correlation across genes: 0.7303738287000091\n",
      "Fold B1 mean correlation across genes:  0.35370891753996103\n",
      "Fold B1 number of genes with correlation > 0.3:  517\n",
      "Fold B1 :Top 50 Genes Mean Pearson Correlation: 0.6109298545118932\n",
      "Fold B1 Top 10 genes with highest correlation:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.7303738287000091\n",
      "Gene ID: 704, Gene Name: STMN1, R: 0.6929894146725173\n",
      "Gene ID: 197, Gene Name: HLA-B, R: 0.68820725855525\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.6858634636546882\n",
      "Gene ID: 733, Gene Name: UBA52, R: 0.6669335511212615\n",
      "Gene ID: 698, Gene Name: HLA-DRA, R: 0.6599089115391091\n",
      "Gene ID: 563, Gene Name: CXCL10, R: 0.6547010608129907\n",
      "Gene ID: 624, Gene Name: BST2, R: 0.6523726988066276\n",
      "Gene ID: 715, Gene Name: IGLC3, R: 0.6522053532656357\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.6471643813071699\n",
      "cluster number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.319\n",
      "cluster number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.252\n",
      "cluster number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.312\n",
      "cluster number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.288\n",
      "cluster number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.275\n",
      "Processing Image C1\n",
      "image query shape:  (176, 256)\n",
      "expression_gt shape:  (176, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([176, 10139])\n",
      "(176, 785)\n",
      "(176, 785)\n",
      "3.2588746547698975\n",
      "3.4836807\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.6813865948761647\n",
      "MSE across cells:  0.20749962044008663\n",
      "RMSE across cells:  0.4555212623358943\n",
      "Max correlation across genes: 0.7775209154667049\n",
      "Fold C1 mean correlation across genes:  0.31718705261213637\n",
      "Fold C1 number of genes with correlation > 0.3:  421\n",
      "Fold C1 :Top 50 Genes Mean Pearson Correlation: 0.6095614646258611\n",
      "Fold C1 Top 10 genes with highest correlation:\n",
      "Gene ID: 328, Gene Name: MGP, R: 0.7775209154667049\n",
      "Gene ID: 227, Gene Name: SCD, R: 0.7765447250133358\n",
      "Gene ID: 431, Gene Name: CLDN4, R: 0.7418182180305909\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.7354138848661179\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.7088249867499148\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.6881231601861952\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.6798827478059078\n",
      "Gene ID: 660, Gene Name: KRT8, R: 0.6760699429266281\n",
      "Gene ID: 89, Gene Name: ITGB6, R: 0.6628024862139278\n",
      "Gene ID: 197, Gene Name: HLA-B, R: 0.655784320838664\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.099\n",
      "cluster number: 3\n",
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.027\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.098\n",
      "cluster number: 3\n",
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.123\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.105\n",
      "Processing Image D1\n",
      "image query shape:  (306, 256)\n",
      "expression_gt shape:  (306, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([306, 10139])\n",
      "(306, 785)\n",
      "(306, 785)\n",
      "2.7603611946105957\n",
      "3.1218235\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.6774986087137128\n",
      "MSE across cells:  0.24519159346335645\n",
      "RMSE across cells:  0.4951682476324148\n",
      "Max correlation across genes: 0.800537847679012\n",
      "Fold D1 mean correlation across genes:  0.23912903713979938\n",
      "Fold D1 number of genes with correlation > 0.3:  196\n",
      "Fold D1 :Top 50 Genes Mean Pearson Correlation: 0.49319748813828185\n",
      "Fold D1 Top 10 genes with highest correlation:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.800537847679012\n",
      "Gene ID: 89, Gene Name: ITGB6, R: 0.6409442839929919\n",
      "Gene ID: 275, Gene Name: C3, R: 0.6314906922794241\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.6175426565129241\n",
      "Gene ID: 736, Gene Name: CD74, R: 0.5761914636153195\n",
      "Gene ID: 14, Gene Name: TXNDC17, R: 0.5665379207157871\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.5377826688835784\n",
      "Gene ID: 783, Gene Name: NDRG1, R: 0.5358085875499824\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.5336735681924664\n",
      "Gene ID: 191, Gene Name: RAB11FIP1, R: 0.5323157834429167\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.273\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.16\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.356\n",
      "cluster number: 3\n",
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.303\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.327\n",
      "Processing Image E1\n",
      "image query shape:  (587, 256)\n",
      "expression_gt shape:  (587, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([587, 10139])\n",
      "(587, 785)\n",
      "(587, 785)\n",
      "3.289362907409668\n",
      "3.4946344\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.7150138701687232\n",
      "MSE across cells:  0.17073682302039525\n",
      "RMSE across cells:  0.4132031256178918\n",
      "Max correlation across genes: 0.5465361953520842\n",
      "Fold E1 mean correlation across genes:  0.18129913826230495\n",
      "Fold E1 number of genes with correlation > 0.3:  106\n",
      "Fold E1 :Top 50 Genes Mean Pearson Correlation: 0.3977087023551698\n",
      "Fold E1 Top 10 genes with highest correlation:\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.5465361953520842\n",
      "Gene ID: 154, Gene Name: MUCL1, R: 0.5435806711582167\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.5251120246396335\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.5102078587064454\n",
      "Gene ID: 431, Gene Name: CLDN4, R: 0.5007848275022152\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.4925542553281491\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.4880191588478679\n",
      "Gene ID: 113, Gene Name: FDPS, R: 0.4637768496384459\n",
      "Gene ID: 182, Gene Name: S100A14, R: 0.46377351702076636\n",
      "Gene ID: 765, Gene Name: LTF, R: 0.45755547850742856\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: -0.016\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.003\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: -0.004\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: -0.003\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: -0.004\n",
      "Processing Image F1\n",
      "image query shape:  (691, 256)\n",
      "expression_gt shape:  (691, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([691, 10139])\n",
      "(691, 785)\n",
      "(691, 785)\n",
      "3.2279176712036133\n",
      "3.5189433\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.6431287514543348\n",
      "MSE across cells:  0.2771359538643484\n",
      "RMSE across cells:  0.5264370369420719\n",
      "Max correlation across genes: 0.6324748661397126\n",
      "Fold F1 mean correlation across genes:  0.18731396350608034\n",
      "Fold F1 number of genes with correlation > 0.3:  100\n",
      "Fold F1 :Top 50 Genes Mean Pearson Correlation: 0.363574946682831\n",
      "Fold F1 Top 10 genes with highest correlation:\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.6324748661397126\n",
      "Gene ID: 507, Gene Name: IGLC2, R: 0.4301629078846443\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.4298318548860491\n",
      "Gene ID: 756, Gene Name: CAPG, R: 0.40609201142336004\n",
      "Gene ID: 636, Gene Name: LUC7L3, R: 0.40132136870325513\n",
      "Gene ID: 451, Gene Name: PLK2, R: 0.3998291507337693\n",
      "Gene ID: 708, Gene Name: MYL9, R: 0.3990112657933905\n",
      "Gene ID: 447, Gene Name: IGHG3, R: 0.3943399846397229\n",
      "Gene ID: 368, Gene Name: RHOB, R: 0.3931750587677727\n",
      "Gene ID: 145, Gene Name: HLA-DPA1, R: 0.3927694363593251\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.003\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: -0.004\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.008\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.01\n",
      "cluster number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.004\n",
      "Processing Image G2\n",
      "image query shape:  (467, 256)\n",
      "expression_gt shape:  (467, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([467, 10139])\n",
      "(467, 785)\n",
      "(467, 785)\n",
      "3.214796304702759\n",
      "3.564969\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.6096632283095837\n",
      "MSE across cells:  0.27298479329255515\n",
      "RMSE across cells:  0.5224794668621487\n",
      "Max correlation across genes: 0.6773509436671871\n",
      "Fold G2 mean correlation across genes:  0.22580273391238387\n",
      "Fold G2 number of genes with correlation > 0.3:  189\n",
      "Fold G2 :Top 50 Genes Mean Pearson Correlation: 0.4818500058063149\n",
      "Fold G2 Top 10 genes with highest correlation:\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.6773509436671871\n",
      "Gene ID: 78, Gene Name: TMEM123, R: 0.6009672275636952\n",
      "Gene ID: 17, Gene Name: POSTN, R: 0.581464413621956\n",
      "Gene ID: 89, Gene Name: ITGB6, R: 0.5742668501398198\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.5677914254436377\n",
      "Gene ID: 746, Gene Name: MYL12B, R: 0.5647281306751941\n",
      "Gene ID: 431, Gene Name: CLDN4, R: 0.5623775436307271\n",
      "Gene ID: 87, Gene Name: FAM193B, R: 0.5525594969624172\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.541549383762844\n",
      "Gene ID: 783, Gene Name: NDRG1, R: 0.5363147326691935\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.217\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.165\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.159\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.139\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/tmp/ipykernel_46476/1266967016.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
      "/tmp/ipykernel_46476/1266967016.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.173\n",
      "Processing Image H1\n",
      "image query shape:  (613, 256)\n",
      "expression_gt shape:  (613, 785)\n",
      "finding matches, using weighted average of top 50 expressions\n",
      "torch.Size([613, 10139])\n",
      "(613, 785)\n",
      "(613, 785)\n",
      "3.31240177154541\n",
      "3.5241778\n",
      "0.0\n",
      "0.0\n",
      "The Prediction: prediction\n",
      "Mean correlation across cells:  0.6524734131032347\n",
      "MSE across cells:  0.20294628023504424\n",
      "RMSE across cells:  0.45049559402400846\n",
      "Max correlation across genes: 0.6319622303525718\n",
      "Fold H1 mean correlation across genes:  0.2058572421022836\n",
      "Fold H1 number of genes with correlation > 0.3:  150\n",
      "Fold H1 :Top 50 Genes Mean Pearson Correlation: 0.43281122542700784\n",
      "Fold H1 Top 10 genes with highest correlation:\n",
      "Gene ID: 311, Gene Name: IGHA1, R: 0.6319622303525718\n",
      "Gene ID: 60, Gene Name: IGKC, R: 0.5954130858853829\n",
      "Gene ID: 698, Gene Name: HLA-DRA, R: 0.5392008919429748\n",
      "Gene ID: 134, Gene Name: GNAS, R: 0.503354220631834\n",
      "Gene ID: 201, Gene Name: VIM, R: 0.4961680364355265\n",
      "Gene ID: 495, Gene Name: FN1, R: 0.49549374374951194\n",
      "Gene ID: 388, Gene Name: A2M, R: 0.48712442636065284\n",
      "Gene ID: 758, Gene Name: HLA-DRB1, R: 0.47922691221993347\n",
      "Gene ID: 145, Gene Name: HLA-DPA1, R: 0.472109871540814\n",
      "Gene ID: 366, Gene Name: FASN, R: 0.4676264736935014\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] ARI: 0.246\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression features ARI: 0.217\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Expression Embeddings ARI: 0.228\n",
      "cluster number: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Reconstruction ARI: 0.25\n",
      "cluster number: 6\n",
      "Fold: [0, 6, 12, 18, 24, 27, 31, 33] Mixed Reconstruction ARI: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "for ID in test_ID:    \n",
    "    print(\"Processing Image\", ID)\n",
    "    image_query = spot_embeddings_dict[ID]\n",
    "    expression_gt = exp_dict[ID].numpy().T\n",
    "\n",
    "    method = \"weighted_average\" # \"average\" \"weighted_average\"\n",
    "    save_path = \"\"\n",
    "    if image_query.shape[1] != 256:\n",
    "        image_query = image_query.T\n",
    "        print(\"image query shape: \", image_query.shape)\n",
    "    if expression_gt.shape[0] != image_query.shape[0]:\n",
    "        expression_gt = expression_gt.T\n",
    "        print(\"expression_gt shape: \", expression_gt.shape)\n",
    "    if spot_key.shape[1] != 256:\n",
    "        spot_key = spot_key.T\n",
    "        print(\"spot_key shape: \", spot_key.shape)\n",
    "    if expression_key.shape[0] != spot_key.shape[0]:\n",
    "        expression_key = expression_key.T\n",
    "        print(\"expression_key shape: \", expression_key.shape)\n",
    "\n",
    "    if method == \"simple\":\n",
    "        indices = find_matches(spot_key, image_query, top_k=1)\n",
    "        matched_spot_embeddings_pred = spot_key[indices[:,0],:]\n",
    "        print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        matched_spot_expression_pred = expression_key[indices[:,0],:]\n",
    "        print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    if method == \"average\":\n",
    "        print(\"finding matches, using average of top 50 expressions\")\n",
    "        indices = find_matches(spot_key, image_query, top_k=50)\n",
    "        matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "        matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "        for i in range(indices.shape[0]):\n",
    "            matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0)\n",
    "            matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0)\n",
    "        \n",
    "        print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    if method == \"weighted_average\":\n",
    "        print(\"finding matches, using weighted average of top 50 expressions\")\n",
    "        indices = find_matches(spot_key, image_query, top_k=100)\n",
    "        # print(\"indices = \", indices)\n",
    "        matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "        matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "        for i in range(indices.shape[0]):\n",
    "            a = np.sum((spot_key[indices[i,0],:] - image_query[i,:])**2) #the smallest MSE\n",
    "            weights = np.exp(-(np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1)-a+1))\n",
    "            # weights = a/np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1)\n",
    "            # a = np.sqrt(np.sum((spot_key[indices[i,0],:] - image_query[i,:])**2)) #the smallest RMSE\n",
    "            # weights = np.exp(-(np.sqrt(np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1))-a+1))\n",
    "            \n",
    "            # sorted_indices = np.argsort(weights)[::-1]  # \n",
    "            # top_10_weights = weights[sorted_indices[:10]]\n",
    "            # least_10_weights = weights[sorted_indices[-10:]]\n",
    "            # print(\"Top 10 weights: \", top_10_weights)\n",
    "            # print(\"least 10 weights: \", least_10_weights)\n",
    "            \n",
    "            # if i == 0:\n",
    "            #     print(\"weights: \", weights)\n",
    "            matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0, weights=weights)\n",
    "            matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0, weights=weights)\n",
    "        \n",
    "        # print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "        # print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "    true = expression_gt\n",
    "    pred = matched_spot_expression_pred\n",
    "    adj = adj_dict[ID]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = './figures/show'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_features = model.spot_encoder(torch.tensor(pred, dtype=torch.float32).cuda(), adj.cuda())\n",
    "        pred_embeddings = model.spot_projection(torch.tensor(pred_features, dtype=torch.float32).cuda())\n",
    "        pred_encoding = model.spot_autoencoder.encode(torch.tensor(pred_embeddings, dtype=torch.float32).cuda(), adj.cuda())\n",
    "        pred_reconstruction, extra = model.spot_autoencoder.decode(torch.tensor(pred_encoding, dtype=torch.float32).cuda())\n",
    "\n",
    "        pred_features = pred_features.cpu().numpy()\n",
    "        pred_embeddings = pred_embeddings.cpu().numpy()\n",
    "        pred_encoding = pred_encoding.cpu().numpy()\n",
    "        pred_reconstruction = pred_reconstruction.cpu().numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "    print(true.shape)\n",
    "    print(np.max(pred))\n",
    "    print(np.max(true))\n",
    "    print(np.min(pred))\n",
    "    print(np.min(true))\n",
    "    \n",
    "    ####### Prediction PCC performance\n",
    "    mix = (pred + pred_reconstruction)/2\n",
    "    \n",
    "    def evaluate_gene_expression(pred, true, ID, top_k, fold, top_results, testset):\n",
    "        # Genewise correlation across cells\n",
    "        corr_cells = np.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            corr_cells[i] = np.corrcoef(pred[i, :], true[i, :])[0, 1]\n",
    "        # Remove NaN\n",
    "        corr_cells = corr_cells[~np.isnan(corr_cells)]\n",
    "        print(\"Mean correlation across cells: \", np.mean(corr_cells))\n",
    "        \n",
    "        # Calculate RMSE across cells\n",
    "        mse_cells = mean_squared_error(pred, true)\n",
    "        rmse_cells = sqrt(mse_cells)\n",
    "        print(\"MSE across cells: \", mse_cells)\n",
    "        print(\"RMSE across cells: \", rmse_cells)\n",
    "        \n",
    "        # Genewise correlation across genes\n",
    "        corr_genes = np.zeros(pred.shape[1])\n",
    "        for i in range(pred.shape[1]):\n",
    "            corr_genes[i] = np.corrcoef(pred[:, i], true[:, i])[0, 1]\n",
    "        # Remove NaN\n",
    "        corr_genes = corr_genes[~np.isnan(corr_genes)]\n",
    "        \n",
    "        if corr_genes.size == 0:\n",
    "            print(\"corr_genes is an empty array\")\n",
    "        elif np.isnan(corr_genes).all():\n",
    "            print(\"corr_genes is an array of NaNs\")\n",
    "        else:\n",
    "            print(\"Max correlation across genes:\", np.nanmax(corr_genes))\n",
    "        \n",
    "        print('Fold', ID, \"mean correlation across genes: \", np.mean(corr_genes))\n",
    "        print('Fold', ID, \"number of genes with correlation > 0.3: \", np.sum(corr_genes > 0.3))\n",
    "        \n",
    "        # Top-k genes\n",
    "        top_k_indices = np.argsort(corr_genes)[-top_k:]\n",
    "        top_R_values = corr_genes[top_k_indices]\n",
    "        top_pred_values = pred[:, top_k_indices]\n",
    "        top_results[ID] = (top_R_values, top_pred_values)\n",
    "        print('Fold', ID, f':Top {top_k} Genes Mean Pearson Correlation:', np.nanmean(top_R_values))\n",
    "        \n",
    "        # Get top gene correlations\n",
    "        top_R_values = get_top_values(corr_genes)\n",
    "        print('Fold', ID, \"Top 10 genes with highest correlation:\")\n",
    "        for gene_id, r_value in top_R_values:\n",
    "            gene_name = testset.gene_set[gene_id]\n",
    "            print(f\"Gene ID: {gene_id}, Gene Name: {gene_name}, R: {r_value}\")\n",
    "\n",
    "    # Example usage:\n",
    "    print(f\"The Prediction: prediction\")\n",
    "    evaluate_gene_expression(pred, true, ID, top_k, fold, top_results, testset)\n",
    "    # print(f\"\\n The Prediction Matrix: pred_reconstruction\")\n",
    "    # evaluate_gene_expression(pred_reconstruction, true, ID, top_k, fold, top_results, testset)\n",
    "    # print(f\"\\n The Prediction Matrix: mix\")\n",
    "    # evaluate_gene_expression(mix, true, ID, top_k, fold, top_results, testset)\n",
    "    \n",
    "    ####### Clustering \n",
    "    ### Change the type of pred to AnnData for the next clustering task\n",
    "    pred = sc.AnnData(pred)\n",
    "    pred.obsm['spatial'] = center_dict[ID]\n",
    "    true = ad.AnnData(true)\n",
    "    true.obsm['spatial'] = center_dict[ID]\n",
    "    pred_features = sc.AnnData(pred_features)\n",
    "    pred_features.obsm['spatial'] = center_dict[ID]\n",
    "    pred_embeddings = sc.AnnData(pred_embeddings)\n",
    "    pred_embeddings.obsm['spatial'] = center_dict[ID]\n",
    "    # pred_encoding = sc.AnnData(pred_encoding)\n",
    "    # pred_encoding.obsm['spatial'] = center_dict[ID]\n",
    "    pred_reconstruction = sc.AnnData(pred_reconstruction)\n",
    "    pred_reconstruction.obsm['spatial'] = center_dict[ID]\n",
    "    mix = sc.AnnData(mix)\n",
    "    mix.obsm['spatial'] = center_dict[ID]\n",
    "\n",
    "    \n",
    "    ####### Generate cluster figure\n",
    "    label = testset.label[ID]\n",
    "    # print(\"label = \",label)\n",
    "    clus, ARI = cluster(pred, label)\n",
    "    print('Fold:', fold, 'ARI:', ARI)\n",
    "    # title = f\"{ID} ARI = {ARI:.3f}\"  # Format title with ARI value   \n",
    "    # sc.pl.spatial(pred, img=testset.get_img(ID), color='kmeans', spot_size=112, title=title, save=f\"/mymodel_Her2_{ID}.pdf\")    \n",
    "    \n",
    "    \n",
    "    # clus, Top_ARI = cluster(top_pred_values, label)\n",
    "    # print('Fold:', fold, 'Top 100 ARI:', Top_ARI)\n",
    "    clus, feature_ARI = cluster(pred_features, label)\n",
    "    print('Fold:', fold, 'Expression features ARI:', feature_ARI)\n",
    "    # title = f\"{ID} ARI = {ARI:.3f}\"  # Format title with ARI value   \n",
    "    # sc.pl.spatial(pred_features, img=testset.get_img(ID), color='kmeans', spot_size=112, title=title, save=f\"/mymodel_Her2_{ID}_features.pdf\")   \n",
    "    \n",
    "    clus, Emb_ARI = cluster(pred_embeddings, label)\n",
    "    print('Fold:', fold, 'Expression Embeddings ARI:', Emb_ARI)\n",
    "    # title = f\"{ID} ARI = {Emb_ARI:.3f}\"  # Format title with ARI value   \n",
    "    # sc.pl.spatial(pred_embeddings, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_Emb.pdf\")\n",
    "\n",
    "    \n",
    "    clus, Re_ARI = cluster(pred_reconstruction, label)\n",
    "    print('Fold:', fold, 'Reconstruction ARI:', Re_ARI)\n",
    "    # title = f\"{ID} ARI = {Re_ARI:.3f}\"  # Format title with ARI value   \n",
    "    # sc.pl.spatial(pred_reconstruction, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_Reconstruction.pdf\")    \n",
    "    \n",
    "    clus, mix_ARI = cluster(mix, label)\n",
    "    print('Fold:', fold, 'Mixed Reconstruction ARI:', mix_ARI)\n",
    "    # title = f\"{ID} ARI = {mix_ARI:.3f}\"  # Format title with ARI value   \n",
    "    # sc.pl.spatial(mix, img=testset.get_img(ID), color='kmeans', spot_size=112, title = title, save=f\"/mymodel_Her2_{ID}_mix.pdf\") \n",
    "\n",
    "    \n",
    "    # print(\"\\n\")\n",
    "    # if save_path != \"\":\n",
    "    #     np.save(save_path + \"matched_spot_embeddings_pred.npy\", matched_spot_embeddings_pred.T)\n",
    "    #     np.save(save_path + \"matched_spot_expression_pred.npy\", matched_spot_expression_pred.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9]\n",
      "{}\n",
      "[[0.90636307 0.01716013 1.27345228 ... 0.96279126 1.40579331 1.40914977]\n",
      " [0.78615433 0.16812551 0.97852707 ... 0.71877563 1.29658175 1.17757511]\n",
      " [0.57783115 0.2906794  0.61150104 ... 0.6798892  1.19054627 0.96232635]\n",
      " ...\n",
      " [0.36123031 0.07967214 0.33944419 ... 0.29751673 0.53201169 0.26382375]\n",
      " [0.15348776 0.07810118 0.2704705  ... 0.17751326 0.44164845 0.21989258]\n",
      " [0.11655529 0.07476368 0.20791259 ... 0.37653571 0.28566301 0.14665827]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_k_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/ICL2ST/model_inference.ipynb 单元格 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(top_results)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(pred)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bssh4.vast.ai/root/ICL2ST/model_inference.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(top_k_indices)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_k_indices' is not defined"
     ]
    }
   ],
   "source": [
    "print(fold)\n",
    "print(top_results)\n",
    "print(pred)\n",
    "print(top_k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613, 785)\n",
      "(613, 785)\n",
      "(613, 256)\n",
      "(613, 785)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(pred_features.shape)\n",
    "print(pred_embeddings.shape)\n",
    "print(pred_reconstruction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
